<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title>SAGE MARK 85 - SMIT'S AI</title>
    <link href="https://fonts.googleapis.com/css2?family=Orbitron:wght@400;700&display=swap" rel="stylesheet">
    <style>
        :root { --gold: #ffcc00; --red: #ff0000; --dark: #0a0000; }
        body { background: var(--dark); color: var(--gold); font-family: 'Orbitron', sans-serif; min-height: 100vh; margin: 0; display: flex; flex-direction: column; align-items: center; justify-content: center; overflow-x: hidden; }
        
        /* THE CORE & VISION HUD */
        #core-container { position: relative; width: 280px; height: 280px; border-radius: 50%; overflow: hidden; border: 4px solid var(--red); box-shadow: 0 0 40px var(--red); background: #000; }
        video { position: absolute; top: 0; left: 0; width: 100%; height: 100%; object-fit: cover; opacity: 0; transition: 1s; filter: sepia(1) hue-rotate(320deg) saturate(4) contrast(1.2); }
        svg { position: absolute; z-index: 10; width: 100%; height: 100%; pointer-events: none; }
        .ring { fill: none; stroke: var(--gold); stroke-width: 2; transform-origin: center; }
        #outer { stroke-dasharray: 40, 20; animation: spin 10s linear infinite; stroke: var(--red); }
        #glow { fill: var(--gold); opacity: 0.1; }
        @keyframes spin { from { transform: rotate(0deg); } to { transform: rotate(360deg); } }

        /* HUD TEXT ELEMENTS */
        #hud { position: absolute; bottom: 8%; text-align: center; width: 100%; }
        #status { font-size: 10px; letter-spacing: 5px; color: var(--red); margin-bottom: 5px; font-weight: bold; }
        #transcript { color: #fff; font-size: 14px; margin-bottom: 15px; min-height: 20px; text-transform: uppercase; text-shadow: 0 0 5px var(--red); }
        
        /* COMMAND BOX */
        input { background: rgba(255, 0, 0, 0.1); border: 2px solid var(--red); color: var(--gold); padding: 15px; width: min(400px, 80vw); font-family: 'Orbitron'; outline: none; text-align: center; box-shadow: 0 0 15px rgba(255,0,0,0.2); transition: 0.3s; }
        input:focus { border-color: var(--gold); box-shadow: 0 0 25px var(--red); }

        /* CONTENT BRIEF */
        #brief { max-width: 860px; padding: 30px 30px 120px; margin-top: 40px; background: rgba(255, 0, 0, 0.08); border: 1px solid rgba(255, 0, 0, 0.5); box-shadow: 0 0 25px rgba(255, 0, 0, 0.2); text-align: left; line-height: 1.6; }
        #brief h1 { font-size: 26px; margin: 0 0 10px; color: #fff; text-transform: uppercase; letter-spacing: 2px; }
        #brief h2 { font-size: 18px; margin: 24px 0 8px; color: var(--gold); text-transform: uppercase; letter-spacing: 2px; }
        #brief h3 { font-size: 15px; margin: 16px 0 6px; color: #fff; text-transform: uppercase; letter-spacing: 1px; }
        #brief p { margin: 0 0 10px; color: #f5e7a4; }
        #brief ul { margin: 0 0 12px 18px; padding: 0; color: #fef7da; }
        #brief li { margin-bottom: 6px; }
        #brief .summary { border-left: 3px solid var(--red); padding-left: 12px; margin-top: 12px; }
        #brief .cta { margin-top: 16px; color: #fff; }

        /* BOOT BUTTON */
        #boot { position: fixed; inset: 0; background: #000; z-index: 1000; display: flex; align-items: center; justify-content: center; }
        #boot button { background: var(--red); color: white; border: none; padding: 25px 60px; font-family: 'Orbitron'; cursor: pointer; font-size: 20px; box-shadow: 0 0 30px var(--red); letter-spacing: 5px; }
    </style>
</head>
<body>

    <div id="boot"><button onclick="bootSystem()">ENGAGE NEURAL LINK</button></div>

    <div id="core-container">
        <video id="webcam" autoplay playsinline></video>
        <svg viewBox="0 0 200 200">
            <circle id="outer" class="ring" cx="100" cy="100" r="90" />
            <circle class="ring" cx="100" cy="100" r="75" stroke-opacity="0.2" />
            <circle id="glow" cx="100" cy="100" r="45" />
            <circle cx="100" cy="100" r="8" fill="#fff" />
        </svg>
    </div>

    <div id="hud">
        <div id="status">MARK 85 SYSTEM: STANDBY</div>
        <div id="transcript">AWAITING INPUT...</div>
        <input type="text" id="cmdInput" placeholder="ENTER COMMAND OR SPEAK...">
    </div>

    <main id="brief">
        <h1>Embodied AI Capability Breakdown</h1>
        <p>An animated, designed AI (often called an embodied AI, virtual avatar, or digital agent) combines art, animation, AI models, and interaction systems. Below is a clear, structured breakdown of what such an AI can do and can have, grouped by capability layers.</p>

        <h2>1. Visual &amp; Design Capabilities (What it looks like)</h2>
        <h3>Core Features</h3>
        <ul>
            <li>2D or 3D animated character</li>
            <li>Custom facial design (human, robot, mascot, fantasy)</li>
            <li>Lip-sync with speech (real-time or pre-rendered)</li>
            <li>Eye tracking and blinking</li>
            <li>Idle animations (breathing, subtle movement)</li>
        </ul>
        <h3>Advanced Visuals</h3>
        <ul>
            <li>Facial expressions (emotion-driven)</li>
            <li>Body language and gestures</li>
            <li>Outfit/skin customization</li>
            <li>Art style control (realistic, anime, cartoon, low-poly)</li>
            <li>Camera framing and cinematic angles</li>
        </ul>
        <p><strong>Example:</strong> A 3D humanoid AI tutor that smiles, nods, and gestures while teaching.</p>

        <h2>2. Intelligence &amp; Thinking (What it knows)</h2>
        <h3>Cognitive Abilities</h3>
        <ul>
            <li>Natural language understanding</li>
            <li>Context-aware conversations</li>
            <li>Memory (short-term and long-term)</li>
            <li>Reasoning and problem-solving</li>
            <li>Multi-step task planning</li>
        </ul>
        <h3>Knowledge Handling</h3>
        <ul>
            <li>General knowledge</li>
            <li>Domain-specific expertise (coding, finance, education)</li>
            <li>Real-time data access (optional)</li>
            <li>Multilingual understanding</li>
        </ul>
        <p><strong>Example:</strong> An animated AI assistant that remembers your preferences and explains topics step-by-step.</p>

        <h2>3. Communication Abilities (How it talks)</h2>
        <h3>Input</h3>
        <ul>
            <li>Text input</li>
            <li>Voice input (speech-to-text)</li>
            <li>Gesture or motion input (via camera)</li>
            <li>Button/UI interaction</li>
        </ul>
        <h3>Output</h3>
        <ul>
            <li>Natural-sounding speech (TTS)</li>
            <li>Emotional voice modulation</li>
            <li>On-screen text and subtitles</li>
            <li>Expressive facial reactions</li>
        </ul>
        <p><strong>Example:</strong> A virtual receptionist that listens, responds verbally, and reacts with facial expressions.</p>

        <h2>4. Emotional &amp; Personality Layer (How it behaves)</h2>
        <h3>Emotional Intelligence</h3>
        <ul>
            <li>Emotion detection from text or voice</li>
            <li>Mood-based responses</li>
            <li>Empathy and tone adaptation</li>
            <li>Personality consistency</li>
        </ul>
        <h3>Personality Design</h3>
        <ul>
            <li>Friendly, serious, playful, professional</li>
            <li>Age and cultural style simulation</li>
            <li>Brand-aligned behavior</li>
            <li>Adjustable intensity (calm vs energetic)</li>
        </ul>
        <p><strong>Example:</strong> A cheerful animated fitness coach that motivates without sounding robotic.</p>

        <h2>5. Interaction &amp; Control (What it can do for users)</h2>
        <h3>Task Execution</h3>
        <ul>
            <li>Answer questions</li>
            <li>Guide users step-by-step</li>
            <li>Control apps or systems</li>
            <li>Trigger animations or scenes</li>
            <li>Manage schedules or reminders</li>
        </ul>
        <h3>System Integration</h3>
        <ul>
            <li>Web apps</li>
            <li>Mobile apps</li>
            <li>Games</li>
            <li>AR/VR environments</li>
            <li>Smart devices</li>
        </ul>
        <p><strong>Example:</strong> An animated AI inside a game that gives quests and reacts to player choices.</p>

        <h2>6. Learning &amp; Adaptation (How it improves)</h2>
        <ul>
            <li>Learns from user behavior</li>
            <li>Adapts communication style</li>
            <li>Improves accuracy with feedback</li>
            <li>Personalizes content delivery</li>
            <li>Updates knowledge dynamically</li>
        </ul>
        <p><strong>Example:</strong> An AI teacher that adjusts difficulty based on the student’s progress.</p>

        <h2>7. Technical &amp; System Features (Behind the scenes)</h2>
        <ul>
            <li>Real-time rendering engines (Unity, Unreal)</li>
            <li>AI model integration (LLMs, vision models)</li>
            <li>Animation state machines</li>
            <li>Voice synthesis engines</li>
            <li>API and plugin support</li>
            <li>Cloud or on-device processing</li>
        </ul>

        <h2>8. Use Cases (Where it’s used)</h2>
        <ul>
            <li>Virtual assistants</li>
            <li>AI tutors and teachers</li>
            <li>Customer support avatars</li>
            <li>Game characters</li>
            <li>Virtual influencers</li>
            <li>Digital therapists (non-clinical)</li>
            <li>Brand mascots</li>
            <li>Metaverse NPCs</li>
        </ul>

        <h2>9. Optional Advanced Capabilities</h2>
        <ul>
            <li>Full-body motion capture</li>
            <li>Real-time emotion mirroring</li>
            <li>Multi-character conversations</li>
            <li>Autonomous decision-making</li>
            <li>Self-directed goal execution</li>
            <li>Persistent identity across platforms</li>
        </ul>

        <div class="summary">
            <h2>Summary (In one line)</h2>
            <p>An animated, designed AI can see, speak, think, remember, express emotion, learn, and visually exist as a character, while interacting naturally with humans across digital environments.</p>
        </div>

        <p class="cta"><strong>If you want, I can also:</strong></p>
        <ul>
            <li>Design a full feature list for your own AI</li>
            <li>Help you choose tech stacks</li>
            <li>Create a roadmap from idea → product</li>
            <li>Explain how to build one step-by-step</li>
        </ul>
        <p><strong>Just tell me your goal.</strong></p>
    </main>

    <script>
        // REPLACE THIS KEY IF IT EXPIRES
        const API_KEY = "AIzaSyDXmKaJNhJaQNSDtpCtNcnGFzRC-WHsGP0"; 
        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        const synth = window.speechSynthesis;

        function bootSystem() {
            document.getElementById('boot').style.display = 'none';
            document.getElementById('status').innerText = "SYSTEMS LIVE - UPLINK ACTIVE";
            speak("Welcome back, Smit. SAGE Protocol is active in the Mark 85 armor. All systems are at your command.");
            startVoice();
        }

        // --- THE BRAIN: HANDLES COMMANDS ---
        async function processCommand(cmd) {
            cmd = cmd.toLowerCase();
            document.getElementById('transcript').innerText = `"${cmd.toUpperCase()}"`;

            // 1. YouTube (Instant System Command)
            if (cmd.includes("youtube")) {
                speak("Accessing YouTube database, Sir.");
                window.open("https://www.youtube.com", "_blank");
                return;
            }

            // 2. Camera/Scan (Instant System Command)
            if (cmd.includes("camera") || cmd.includes("scan") || cmd.includes("vision")) {
                speak("Engaging vision HUD. Scanning environment.");
                try {
                    const stream = await navigator.mediaDevices.getUserMedia({ video: true });
                    const video = document.getElementById('webcam');
                    video.srcObject = stream;
                    video.style.opacity = "1";
                } catch (e) { speak("Sir, camera sensors are blocked by the OS."); }
                return;
            }

            // 3. Search (Instant System Command)
            if (cmd.includes("search") || cmd.includes("google")) {
                let query = cmd.replace("search", "").replace("google", "");
                speak(`Searching the archives for ${query}.`);
                window.open(`https://www.google.com/search?q=${query}`, "_blank");
                return;
            }

            // 4. General Questions (AI Brain Uplink)
            document.getElementById('status').innerText = "QUERYING CLOUD...";
            const response = await askGemini(cmd);
            speak(response);
            document.getElementById('status').innerText = "SYSTEMS LIVE - UPLINK ACTIVE";
        }

        async function askGemini(query) {
            const endpoint = `https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?key=${API_KEY}`;
            try {
                const res = await fetch(endpoint, {
                    method: "POST",
                    headers: { "Content-Type": "application/json" },
                    body: JSON.stringify({ contents: [{ parts: [{ text: `You are SAGE, the AI assistant for Smit. You live in his Iron Man Mark 85 armor. Be witty, sophisticated, and call him Sir. Answer briefly. Query: ${query}` }] }] })
                });
                
                const data = await res.json();
                if (data.error) throw new Error(data.error.message);
                return data.candidates[0].content.parts[0].text;
            } catch (err) {
                console.error(err);
                return "Sir, the network bridge is failing. Please run me through a server like GitHub Pages to enable my brain.";
            }
        }

        // --- INPUT CONTROLS ---
        document.getElementById('cmdInput').addEventListener('keypress', (e) => {
            if (e.key === 'Enter') {
                processCommand(e.target.value);
                e.target.value = "";
            }
        });

        function startVoice() {
            try { recognition.start(); } catch(e) {}
        }

        recognition.onresult = (e) => processCommand(e.results[0][0].transcript);
        recognition.onend = () => { if(!synth.speaking) startVoice(); };

        function speak(text) {
            synth.cancel(); 
            const utter = new SpeechSynthesisUtterance(text);
            const voices = synth.getVoices();
            // Try to find a cool British male voice
            utter.voice = voices.find(v => v.lang.includes('en-GB') && v.name.includes('Male')) || voices[0];
            utter.pitch = 0.85;
            utter.onend = () => startVoice();
            synth.speak(utter);
        }

        window.speechSynthesis.onvoiceschanged = () => synth.getVoices();
    </script>
</body>
</html>
